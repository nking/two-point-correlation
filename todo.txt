-- clean redundant user entries in amazon food reviews
   class AmazonFoodReviewsReaderWriter

    same product with different flavor or other characteristic, a 'variant' of
    the product.
    see https://medium.com/@pradhanshradhanjali300/amazon-fine-food-reviews-analysis-3874550a85ad
    and https://www.kaggle.com/code/naushads/1-2-amazon-fine-food-reviews-eda-data-cleaning-fe

    to use sub-samples of the full dataset, we need to reduce those multiple entries for a user
    for variants of the same product (variants have different productIds)
    into single entries.

    to correct, need to resolve those productIds and decide the first of them in 
    alphabetical order will be the canonical name, then rename the other productIds 
    in the redundant group to the chosen canonical name.
    then remove redunant entries.  will also provide a few different cleaned outputs.
    -- find redundant entries by user to define product groups
    -- make an alias map for the product group, choosing the first member to be the
       canonical name
    -- rename productids to the canonical name and remove redundancies
    -- rewrite the file as _cleaned.csv
    -- write 2 more versions of the file:
       -- sorted by degeneracy using Matula-Beck Degeneracy ordering where
         a vertex is an entry and the edge between vertexes is due to having
         same productId.  write the file as _cleaned_sort_deg_ordering.csv
       -- sorted by productId.  write the file as _cleaned_sort_prod.csv

-- consider using the jax API and sparse matrices in place of CURDecomposition
   in ClusterRecipesTest.java, but in a python script

-- explore the union of Fast DCov algorithm
   and sketches in a streaming context
   also 
       Dai et al. 2015, "Active Sampling Count Sketch (ASCS) for Online Sparse Estimation of a Trillion Scale Covariance Matrix"

   
-- edit the README.txt and documentation
-- update the wiki github io web pages
   -- redo a couple of "other" snapshots on two-pt-correl web page:
   the dbscan and the curved arrow from the finnish data set

-- this project needs 2 different builds and the explanation
   added to both added to README.txt and a note considering 
   mvn to make version control clearer.
   (1) build including shared and trove
   (2) build excluding shared and trove
   -- add the dependency information to the build missing the
      shared class files

-- create ability for multiple dimensions
   -- though with very high dimensions the distances between points is
      not a good indicator for clustering.
-- need improvements in hist...

-- sparse distance transform:
   Line-based recognition using a multidimensional Hausdorff distance
Article in IEEE Transactions on Pattern Analysis and Machine Intelligence · October 1999 DOI: 10.1109/34.790430 · Source: IEEE Xplore

-- add back in some of the GEV context

-- consider 3-d tests and projection effects in critical separation
   threshold for clustering

